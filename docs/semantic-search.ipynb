{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7Lc9I6taO3k"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pinecone-io/examples/blob/master/docs/semantic-search.ipynb) [![Open nbviewer](https://raw.githubusercontent.com/pinecone-io/examples/master/assets/nbviewer-shield.svg)](https://nbviewer.org/github/pinecone-io/examples/blob/master/docs/semantic-search.ipynb)\n",
        "\n",
        "# Semantic Search\n",
        "\n",
        "In this walkthrough, we'll learn how to use Pinecone for semantic search using a multilingual translation dataset. We'll grab English sentences and search over a corpus of related sentences, aiming to find the relevant subset to our query.\n",
        "\n",
        "\n",
        "Semantic search is a form of retrieval that allows you to find documents that are similar in meaning to a given query, irrespective of the words used in each query. Semantic search is often in opposition to lexical search, where keywords are used to identify relevant documents to a given query, though it doesn't have to always be this way!\n",
        "\n",
        " It's super helpful for applications that require an understanding of a query's intent (such as when a user queries with a question over a corpus), or for when traditional lexical search doesn't work (such as in multimodal or multilingual applications).\n",
        "\n",
        "\n",
        "To begin, let's install the following libraries:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q03L1BYEZQfe"
      },
      "outputs": [],
      "source": [
        "!pip install -qU \\\n",
        "  pinecone==6.0.2 \\\n",
        "  pinecone-notebooks==0.1.1 \\\n",
        "  datasets==3.5.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xmobBcgqKEL"
      },
      "source": [
        "---\n",
        "\n",
        "ðŸš¨ _Note: the above `pip install` is formatted for Jupyter notebooks. If running elsewhere you may need to drop the `!`._\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrSfFiIC5roI"
      },
      "source": [
        "## Setting up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VHdin76Nmvl4",
        "outputId": "74805f6a-43f7-42fa-c7a9-b310135b92a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pinecone API key not found in environment.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "def get_pinecone_api_key():\n",
        "    \"\"\"\n",
        "    Get Pinecone API key from environment variable or prompt user for input.\n",
        "    Returns the API key as a string.\n",
        "\n",
        "    Only necessary for notebooks. When using Pinecone yourself,\n",
        "    you can use environment variables or the like to set your API key.\n",
        "    \"\"\"\n",
        "    api_key = os.environ.get(\"PINECONE_API_KEY\")\n",
        "\n",
        "    if api_key is None:\n",
        "        try:\n",
        "            # Try Colab authentication if available\n",
        "            from pinecone_notebooks.colab import Authenticate\n",
        "            Authenticate()\n",
        "            # If successful, key will now be in environment\n",
        "            api_key = os.environ.get(\"PINECONE_API_KEY\")\n",
        "        except ImportError:\n",
        "            # If not in Colab or authentication fails, prompt user for API key\n",
        "            print(\"Pinecone API key not found in environment.\")\n",
        "            api_key = getpass(\"Please enter your Pinecone API key: \")\n",
        "            # Save to environment for future use in session\n",
        "            os.environ[\"PINECONE_API_KEY\"] = api_key\n",
        "\n",
        "    return api_key\n",
        "\n",
        "api_key = get_pinecone_api_key()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mc66NEBAcQHY",
        "outputId": "b7cd8b7f-0077-4839-ba34-d05f5966060e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/miniconda3/envs/pinecone-examples/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from pinecone import Pinecone\n",
        "\n",
        "# Initialize client\n",
        "\n",
        "pc = Pinecone(\n",
        "        # You can remove this for your own projects!\n",
        "        api_key=api_key,\n",
        "        source_tag=\"pinecone_examples:docs:semantic-search\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ap1U_NCFmvl5"
      },
      "source": [
        "### Creating a Pinecone Index with Integrated Inference\n",
        "\n",
        "Typically, semantic search requires three pieces: a processed data source (chunks, or records in Pinecone), an embedding model, and a vector database.\n",
        "\n",
        "Integrated Inference allows you to specify the creation of a Pinecone index with a specific Pinecone-hosted embedding model, which makes it easy to interact with the index. To learn more about Integrated Inference, including what other models are available, take a [look here](https://docs.pinecone.io/guides/get-started/overview#integrated-embedding).\n",
        "\n",
        "\n",
        "Here, we specify a starter tier index with the [llama-text-embed-v2](https://docs.pinecone.io/models/llama-text-embed-v2) embedding model. We also specify a mapping for what field in our records we will embed with this model. Then, we grab the index we just created for embedding later.\n",
        "\n",
        "Want to instead embed a subset with multiple languages? Use the [multilingual-e5-large model](https://docs.pinecone.io/models/multilingual-e5-large) and simply specify this inplace of the previous model when creating an index."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kT8pfoO46Iwg"
      },
      "outputs": [],
      "source": [
        "\n",
        "index_name = \"semantic-search\"\n",
        "\n",
        "if not pc.has_index(index_name):\n",
        "    pc.create_index_for_model(\n",
        "        name=index_name,\n",
        "        cloud=\"aws\",\n",
        "        region=\"us-east-1\",\n",
        "        embed={\n",
        "            # Use this if you want to instead embed non-english or a multilingual subset of the data\n",
        "            #\"model\":\"multilingual-e5-large\",\n",
        "            \"model\": \"llama-text-embed-v2\",\n",
        "            \"field_map\":{\"text\": \"chunk_text\"}\n",
        "        }\n",
        "    )\n",
        "\n",
        "# Initialize index client\n",
        "index = pc.Index(name=index_name)\n",
        "\n",
        "# View index stats\n",
        "index.describe_index_stats()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awQY-UGimvl6"
      },
      "source": [
        "## Creating our dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEMbGlWqmvl6"
      },
      "source": [
        "We're working with a small subset of a large multilingual dataset called Tatoeba. Tatoeba consists of hundreds of thousands of sentence translation pairs, and sometimes serves as a benchmark for crosslingual semantic search capabilities.\n",
        "\n",
        "In this notebook, we're just testing semantic search, so we'll grab a subset of english sentences that include the word \"park\".\n",
        "\n",
        "Why \"park\"? In English, park has multiple meanings which occur in different contexts. It could mean a place, such as a public park. Or, it could mean an action with a car (to park) or a place (park-ing spot). Semantic search using embedding models will naturally distinguise between these contexts, without invervention or labeling!\n",
        "\n",
        "This is the key benefit for semantic search; a way to abstract and represent the meaning of user queries without any additional work.\n",
        "\n",
        "And, since our embedding model is inherently multilingual, we can even do this semantic search across several languages without any additional work!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Vq3bwZEJmvl6",
        "outputId": "ce31d581-d8bc-4057-d044-73a2778301cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527,
          "referenced_widgets": [
            "27f8a1488aef4304b6a6445c228fc064",
            "f027611008634c84a8572e82b0729a12",
            "a6a4f1f3dd4e48dcb9e395f486758f43",
            "beba87e90741494fbf42c02db0060b80",
            "dfc6aaac77624e11a1224243ac2f8f4d",
            "c42b431b1e594ed3879c6763d7708cb9",
            "b90a02028b934e73adcd8b7e7b7f9b6b",
            "b406a2a0480145ffac34988e8b9aca98",
            "1a1e8d86b798422d957e5cc22f234897",
            "73dab92cb75145b994d81d0904f162e7",
            "1d0d8b49c5e844af926aa5588c5c1298",
            "1c45794195a3480aa19d0c84cf82a6fe",
            "f16db6147f82431bbd9a39ce9f2dc92c",
            "8896195e3c3d4009a24a6895c806e5d1",
            "92bdf69ba7fd48c99bd3f6465f23dba7",
            "bcc90a36bc25471a970a20d0a246d1f8",
            "016b6bc620ff40fe9455a8cfd8bf7366",
            "2e9545e795d442a19655bdcc394a5d8b",
            "2ed873231d6f40779604f11859b0585c",
            "874e4993deb046b7be146ce6249b146c",
            "51ba5ec315c547df86909eb0d8078dde",
            "0521849baff14166b6420c820081a049"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/4.41k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "27f8a1488aef4304b6a6445c228fc064"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/8.93k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1c45794195a3480aa19d0c84cf82a6fe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "BuilderConfig.__init__() got an unexpected keyword argument 'trust_remote_code'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-4ab292d86346>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# specify that we want the english-spanish translation pairs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtatoeba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Helsinki-NLP/tatoeba\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"en\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"es\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrust_remote_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/load.py\u001b[0m in \u001b[0;36mload_dataset\u001b[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, ignore_verifications, keep_in_memory, save_infos, revision, token, use_auth_token, task, streaming, num_proc, storage_options, **config_kwargs)\u001b[0m\n\u001b[1;32m   2110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2111\u001b[0m     \u001b[0;31m# Create a dataset builder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2112\u001b[0;31m     builder_instance = load_dataset_builder(\n\u001b[0m\u001b[1;32m   2113\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2114\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/load.py\u001b[0m in \u001b[0;36mload_dataset_builder\u001b[0;34m(path, name, data_dir, data_files, cache_dir, features, download_config, download_mode, revision, token, use_auth_token, storage_options, **config_kwargs)\u001b[0m\n\u001b[1;32m   1833\u001b[0m     \u001b[0mbuilder_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_dataset_builder_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1834\u001b[0m     \u001b[0;31m# Instantiate the dataset builder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1835\u001b[0;31m     builder_instance: DatasetBuilder = builder_cls(\n\u001b[0m\u001b[1;32m   1836\u001b[0m         \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1837\u001b[0m         \u001b[0mdataset_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/builder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, cache_dir, dataset_name, config_name, hash, base_path, info, features, token, use_auth_token, repo_id, data_files, data_dir, storage_options, writer_batch_size, name, **config_kwargs)\u001b[0m\n\u001b[1;32m    371\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata_dir\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m             \u001b[0mconfig_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"data_dir\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 373\u001b[0;31m         self.config, self.config_id = self._create_builder_config(\n\u001b[0m\u001b[1;32m    374\u001b[0m             \u001b[0mconfig_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0mcustom_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/builder.py\u001b[0m in \u001b[0;36m_create_builder_config\u001b[0;34m(self, config_name, custom_features, **config_kwargs)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m\"version\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_kwargs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"VERSION\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVERSION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m                 \u001b[0mconfig_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"version\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVERSION\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m             \u001b[0mbuilder_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBUILDER_CONFIG_CLASS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;31m# otherwise use the config_kwargs to overwrite the attributes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.cache/huggingface/modules/datasets_modules/datasets/Helsinki-NLP--tatoeba/b3ea9c6bb2af47699c5fc0a155643f5a0da287c7095ea14824ee0a8afd74daf6/tatoeba.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, lang1, lang2, date, *args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mTatoebaConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBuilderConfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_DATE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m     64\u001b[0m             \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"{lang1}-{lang2}\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: BuilderConfig.__init__() got an unexpected keyword argument 'trust_remote_code'"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "# specify that we want the english-spanish translation pairs\n",
        "tatoeba = load_dataset(\"Helsinki-NLP/tatoeba\", lang1=\"en\", lang2=\"es\", trust_remote_code=True, split=\"train\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQP8n-kLmvl7"
      },
      "source": [
        "Let's take a quick look at a few data points"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rXW0XxoZmvl7"
      },
      "outputs": [],
      "source": [
        "tatoeba[0:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FKvOmSwwmvl7",
        "outputId": "05f377f6-b02c-4740-f1e9-871921254b52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'tatoeba' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-43ef46b9e279>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0mrecords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform_dataset_for_pinecone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtatoeba\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'tatoeba' is not defined"
          ]
        }
      ],
      "source": [
        "keywords= [\"park\"]\n",
        "\n",
        "def simple_keyword_filter(sentence, keywords):\n",
        "  # filter for a list of keywords by sentence\n",
        "  # This is really just for making a toy example quickly, not useful for production.\n",
        "    for keyword in keywords:\n",
        "        if keyword in sentence:\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "def transform_dataset_for_pinecone(dataset, use_filter=True):\n",
        "    # Feel free to adjust this code to simulate a larger search!\n",
        "\n",
        "    if use_filter:\n",
        "        # filter for a list of keywords by sentence, helpful for building intuition on semantic search\n",
        "        translation_pairs = dataset.filter(lambda x: simple_keyword_filter(\n",
        "        sentence = x[\"translation\"][\"en\"], keywords=keywords))\n",
        "    else:\n",
        "        # use the full 200k+ dataset. Run only if you want to embed this many records!\n",
        "        translation_pairs = dataset\n",
        "\n",
        "    # flatten and shuffle for ease of use\n",
        "    translation_pairs = translation_pairs.flatten()\n",
        "    translation_pairs = translation_pairs.shuffle(seed=1)\n",
        "\n",
        "    # If you want to include the spanish subset, simply repeat the below steps with \"es\" instead of \"en\"\n",
        "    # Be sure to create your index with multilingual-e5-large as well in this case!\n",
        "    english_sentences = translation_pairs.rename_column(\"translation.en\", \"text\").remove_columns(\"translation.es\")\n",
        "\n",
        "    # add lang column to indicate embedding origin\n",
        "    english_sentences = english_sentences.add_column(\"lang\", [\"en\"]*len(english_sentences))\n",
        "\n",
        "\n",
        "    records = []\n",
        "\n",
        "    for idx, sentence in enumerate(english_sentences):\n",
        "        # Here, we create a record for each sentence in the dataset\n",
        "        # The record contains an ID and metadata fields which we can use to filter if desired\n",
        "        # The chunk_text field is the text we will embed\n",
        "        records.append(\n",
        "            {\n",
        "                \"id\": str(idx),\n",
        "                \"chunk_text\": sentence[\"text\"],\n",
        "                \"lang\": sentence[\"lang\"]\n",
        "            }\n",
        "        )\n",
        "\n",
        "    # convert to record format\n",
        "    return records\n",
        "\n",
        "\n",
        "records = transform_dataset_for_pinecone(tatoeba)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBV6TWY5mvl7"
      },
      "source": [
        "## Upserting data into the Pinecone index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0O6qOTimvl7"
      },
      "source": [
        "Here, we embed and upsert the data into Pinecone. What this means is that each record we formatted above will interact with our embedding model we specified prior, and produce a vector embedding. Then, we take these embedding batches and store them in Pinecone with the additional information we specified, which is also known as metadata.\n",
        "\n",
        "Metadata is handy for things like filtering, like for if you stored several languages in the same index and want to return just one based on metadata. To learn more about metadata, take a [look here](https://docs.pinecone.io/guides/index-data/indexing-overview#metadata).\n",
        "\n",
        "We specify and create a namespace called \"english-sentences\", which is a higher level unit of organization when interacting with Pinecone.\n",
        "\n",
        "Querying on namespaces performs a sort of broad filter to only records that exist in that namespace, which has the nice effect of speeding up searches too.\n",
        "\n",
        "To learn more about namespaces, [look here](https://docs.pinecone.io/guides/index-data/indexing-overview#namespaces)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "6c9efda7c7394404814e7466d4a9108c",
            "ee94a2a6c50b4abd89fdea7dc2c51b0b",
            "1af0d3d6e7a0465a91fd27a916a0508a",
            "86cf0f742de14c4f95fa5ddb74e07985",
            "ab1007c06e414b2da35507a90e91e8cb",
            "640ee2f088814e6c80014be268749820",
            "e1d5e0366eee4a96bf4a52ee84698c6a",
            "726dc10996c5403d8b0d661a3a6cdb63",
            "1e213f554e8f4c18a96bc71b56d8582a",
            "c62d67ae4d0e498fbf330db34ca8f9e3",
            "15e5e36e202c40fba34e92adfe8aa8de"
          ]
        },
        "id": "RhR6WOi1huXZ",
        "outputId": "9ae50bfe-3ebf-4d8b-e28e-3230aed0e1d7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Upserting records batch: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:02<00:00,  1.79it/s]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "batch_size = 96\n",
        "namespace = \"english-sentences\"\n",
        "\n",
        "\n",
        "# We upsert in batches of 96 to avoid hitting the embedding model's rate limit.\n",
        "# Libraries like backoff can be used here to handler large embedding jobs.\n",
        "\n",
        "for start in tqdm(range(0, len(records), batch_size), f\"Upserting records batch: \"):\n",
        "    index.upsert_records(records=records[start:start+batch_size], namespace = namespace)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VrK_IN079Vuu"
      },
      "source": [
        "## Making Queries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rr4unPAq9alb"
      },
      "source": [
        "Now that our index is populated we can begin making queries.\n",
        "\n",
        "The tricky part about querying with semantic search is that we'd normally need to involve an embedding model here again too!\n",
        "\n",
        "But with Pinecone's Integrated Inference, we can just invoke our index we created and send the text we want to search with there. Specifically,\n",
        "the search query is vectorized using the same embedding model we specified prior, and we use this vector to find all closest vectors in the database to it to return.\n",
        "\n",
        "Neat!\n",
        "\n",
        "Our goal here is to write a query sentence that uses one form of the word park, and find sentences that use park in a semantically similar manner. So, let's try this:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jY8j5_Nsmvl8",
        "outputId": "cbce41ad-4384-4061-a249-543ad5eb0157"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentence: I have the afternoon off today, so I plan to go to the park, sit under a tree and read a book. Semantic Similarity Score: 0.4675264060497284\n",
            "\n",
            "Sentence: I went to the park to play tennis. Semantic Similarity Score: 0.4330753684043884\n",
            "\n",
            "Sentence: I go to the park. Semantic Similarity Score: 0.4261631369590759\n",
            "\n",
            "Sentence: I went to the park yesterday. Semantic Similarity Score: 0.42239895462989807\n",
            "\n",
            "Sentence: I went to the park last Sunday. Semantic Similarity Score: 0.42069774866104126\n",
            "\n",
            "Sentence: I like going for a walk in the park. Semantic Similarity Score: 0.41970351338386536\n",
            "\n",
            "Sentence: I went to the park last Saturday. Semantic Similarity Score: 0.4103226661682129\n",
            "\n",
            "Sentence: I need light plates because today my family is going to eat lunch in the park. Semantic Similarity Score: 0.40211308002471924\n",
            "\n",
            "Sentence: Linda went to the park to listen to music. Semantic Similarity Score: 0.4012303650379181\n",
            "\n",
            "Sentence: I'll go to the park. Semantic Similarity Score: 0.3996794819831848\n",
            "\n"
          ]
        }
      ],
      "source": [
        "search_query = \"I want to go to the park and relax\"\n",
        "\n",
        "results = index.search(\n",
        "    namespace=namespace,\n",
        "    query={\n",
        "        \"top_k\": 10,\n",
        "        \"inputs\": {\n",
        "            'text': search_query\n",
        "        }\n",
        "    }\n",
        ")\n",
        "\n",
        "for result in results[\"result\"][\"hits\"]:\n",
        "    print(f'Sentence: {result[\"fields\"][\"chunk_text\"]} Semantic Similarity Score: {result[\"_score\"]}\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrIcyZ89mvl8"
      },
      "source": [
        "And now, let's use the other meaning of the word, park!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ylxtxY26mvl8",
        "outputId": "d325c03e-4936-4a3b-c609-3b1dba4d16fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentence: I can't find a spot to park my spaceship. Semantic Similarity Score: 0.44190075993537903\n",
            "\n",
            "Sentence: I can't find a spot to park my spaceship. Semantic Similarity Score: 0.44190075993537903\n",
            "\n",
            "Sentence: There isn't anywhere else to park. Semantic Similarity Score: 0.4017431437969208\n",
            "\n",
            "Sentence: I have to park my car here. Semantic Similarity Score: 0.3978813886642456\n",
            "\n",
            "Sentence: Where can I park? Semantic Similarity Score: 0.39125218987464905\n",
            "\n",
            "Sentence: Where can I park? Semantic Similarity Score: 0.39125218987464905\n",
            "\n",
            "Sentence: I am parking my car near the office. Semantic Similarity Score: 0.37668246030807495\n",
            "\n",
            "Sentence: May I park here for a while? Semantic Similarity Score: 0.3707844614982605\n",
            "\n",
            "Sentence: I parked on the left side of the street just in front of the school. Semantic Similarity Score: 0.37002164125442505\n",
            "\n",
            "Sentence: Where can I park my car? Semantic Similarity Score: 0.3609045743942261\n",
            "\n"
          ]
        }
      ],
      "source": [
        "search_query = \"I need a place to park\"\n",
        "\n",
        "results = index.search(\n",
        "    namespace=namespace,\n",
        "    query={\n",
        "        \"top_k\": 10,\n",
        "        \"inputs\": {\n",
        "            'text': search_query\n",
        "        }\n",
        "    }\n",
        ")\n",
        "\n",
        "for result in results[\"result\"][\"hits\"]:\n",
        "    print(f'Sentence: {result[\"fields\"][\"chunk_text\"]} Semantic Similarity Score: {result[\"_score\"]}\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Exhr8up7mvl8"
      },
      "source": [
        "## Wait, how is this working?\n",
        "\n",
        "When performing semantic search with Pinecone's vector database, you are asking the following question: Given this query vector, what are the closest vectors to it in the database?\n",
        "\n",
        "Because of the way embedding models are trained, this closeness in vector space corresponds to similarity in meaning. The exact metric used for our implementation is cosine similarity, which is simply the angle between the input vector and a document vector. For small amounts of vectors, this task is trivial, but what happens when you have hundreds of thousands, millions or even billions? And what about query latency?\n",
        "\n",
        "The magic of Pinecone's vector database is advanced algorithms that can quickly index and do this search on billion-scale vectors effectively!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QENCOdLQmvl8"
      },
      "source": [
        "## Demo Cleanup\n",
        "\n",
        "You can go ahead and ask more queries above. When you're done, delete the index to save resources.\n",
        "\n",
        "Congrats, you've just implemented semantic search with Pinecone!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-cWdeKzhAtww"
      },
      "outputs": [],
      "source": [
        "#pc.delete_index(name=index_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2B0zxR6hbf5d"
      },
      "source": [
        "---"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "27f8a1488aef4304b6a6445c228fc064": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f027611008634c84a8572e82b0729a12",
              "IPY_MODEL_a6a4f1f3dd4e48dcb9e395f486758f43",
              "IPY_MODEL_beba87e90741494fbf42c02db0060b80"
            ],
            "layout": "IPY_MODEL_dfc6aaac77624e11a1224243ac2f8f4d"
          }
        },
        "f027611008634c84a8572e82b0729a12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c42b431b1e594ed3879c6763d7708cb9",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_b90a02028b934e73adcd8b7e7b7f9b6b",
            "value": "Downloadingâ€‡builderâ€‡script:â€‡100%"
          }
        },
        "a6a4f1f3dd4e48dcb9e395f486758f43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b406a2a0480145ffac34988e8b9aca98",
            "max": 4407,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1a1e8d86b798422d957e5cc22f234897",
            "value": 4407
          }
        },
        "beba87e90741494fbf42c02db0060b80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73dab92cb75145b994d81d0904f162e7",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_1d0d8b49c5e844af926aa5588c5c1298",
            "value": "â€‡4.41k/4.41kâ€‡[00:00&lt;00:00,â€‡247kB/s]"
          }
        },
        "dfc6aaac77624e11a1224243ac2f8f4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c42b431b1e594ed3879c6763d7708cb9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b90a02028b934e73adcd8b7e7b7f9b6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b406a2a0480145ffac34988e8b9aca98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a1e8d86b798422d957e5cc22f234897": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "73dab92cb75145b994d81d0904f162e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d0d8b49c5e844af926aa5588c5c1298": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c45794195a3480aa19d0c84cf82a6fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f16db6147f82431bbd9a39ce9f2dc92c",
              "IPY_MODEL_8896195e3c3d4009a24a6895c806e5d1",
              "IPY_MODEL_92bdf69ba7fd48c99bd3f6465f23dba7"
            ],
            "layout": "IPY_MODEL_bcc90a36bc25471a970a20d0a246d1f8"
          }
        },
        "f16db6147f82431bbd9a39ce9f2dc92c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_016b6bc620ff40fe9455a8cfd8bf7366",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_2e9545e795d442a19655bdcc394a5d8b",
            "value": "Downloadingâ€‡readme:â€‡100%"
          }
        },
        "8896195e3c3d4009a24a6895c806e5d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ed873231d6f40779604f11859b0585c",
            "max": 8928,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_874e4993deb046b7be146ce6249b146c",
            "value": 8928
          }
        },
        "92bdf69ba7fd48c99bd3f6465f23dba7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51ba5ec315c547df86909eb0d8078dde",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_0521849baff14166b6420c820081a049",
            "value": "â€‡8.93k/8.93kâ€‡[00:00&lt;00:00,â€‡374kB/s]"
          }
        },
        "bcc90a36bc25471a970a20d0a246d1f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "016b6bc620ff40fe9455a8cfd8bf7366": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e9545e795d442a19655bdcc394a5d8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2ed873231d6f40779604f11859b0585c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "874e4993deb046b7be146ce6249b146c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "51ba5ec315c547df86909eb0d8078dde": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0521849baff14166b6420c820081a049": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}